{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302dbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\envs\\ai_env\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "# 数据增强\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)), \n",
    "    layers.RandomRotation(0.2),  \n",
    "    layers.RandomZoom(0.2),   \n",
    "    layers.RandomContrast(0.1), \n",
    "    layers.RandomBrightness(0.1) \n",
    "    \n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaca355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 'C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\train' 检测到 4 个类别: ['glass', 'metal', 'paper', 'plastic']\n",
      "\n",
      "开始构建模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15804\\4268931668.py:33: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型选择与构建完成。\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import os \n",
    "\n",
    "# 迁移学习模型构建\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "# --- 动态获取类别数量 ---\n",
    "TRAIN_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\train\"  \n",
    "\n",
    "try:\n",
    "    # 获取 TRAIN_DIR 下的子文件夹数量作为类别数\n",
    "    class_names = [name for name in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, name))]\n",
    "    NUM_CLASSES = len(class_names)\n",
    "    print(f\"从 '{TRAIN_DIR}' 检测到 {NUM_CLASSES} 个类别: {class_names}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"训练目录 '{TRAIN_DIR}' 未找到。请确保路径正确并已完成数据集划分。\")\n",
    "except Exception as e:\n",
    "    print(f\"获取类别数量时出错: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n开始构建模型...\")\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3), name=\"input_image\")\n",
    "\n",
    "# 加载预训练的基础模型 \n",
    "base_model = MobileNetV2(\n",
    "    input_tensor=input_tensor,\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    ")\n",
    "\n",
    "# 冻结基础模型的权重\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "#     添加全局平均池化层 (Global Average Pooling)\n",
    "x = GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n",
    "\n",
    "#     添加 Dropout 层\n",
    "x = Dropout(0.5, name=\"dropout_layer\")(x)\n",
    "\n",
    "\n",
    "#     添加最终的输出层 (Prediction Layer)\n",
    "output_tensor = Dense(NUM_CLASSES, activation='softmax', name=\"output_predictions\")(x)\n",
    "\n",
    "model = Model(inputs=input_tensor, outputs=output_tensor, name=\"GarbageClassifier_MobileNetV2\")\n",
    "\n",
    "\n",
    "print(\"\\n模型选择与构建完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b2fc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始准备数据加载器...\n",
      "  从 'C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\train' 创建训练数据集加载器...\n",
      "Found 9291 files belonging to 4 classes.\n",
      "  从 'C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\validation' 创建验证数据集加载器...\n",
      "Found 1991 files belonging to 4 classes.\n",
      "\n",
      "训练集和验证集的数据加载器已准备完毕并进行了性能优化。\n",
      "  - 批次大小 (Batch Size): 32\n",
      "  - 训练集将应用数据增强和模型预处理。\n",
      "  - 验证集将只应用模型预处理。\n",
      "\n",
      "检查一批数据的形状:\n",
      "  - 图片批次形状: (32, 224, 224, 3)\n",
      "  - 标签批次形状: (32, 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 图像尺寸\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "\n",
    "TRAIN_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\train\"     \n",
    "VALIDATION_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\validation\" \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as model_specific_preprocess_input\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n开始准备数据加载器...\")\n",
    "\n",
    "#  定义一个通用的数据预处理函数\n",
    "\n",
    "def preprocess_data(image, label, is_training=False):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    if is_training:\n",
    "        # 对训练数据应用数据增强管道\n",
    "        image = data_augmentation_pipeline(image, training=True)\n",
    "    image = model_specific_preprocess_input(image)\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "#  创建训练数据集加载器\n",
    "print(f\"  从 '{TRAIN_DIR}' 创建训练数据集加载器...\")\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    labels='inferred',          \n",
    "    label_mode='categorical',  \n",
    "                                \n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH), # 将所有图片调整到指定尺寸\n",
    "    interpolation='nearest',    \n",
    "    batch_size=BATCH_SIZE,      \n",
    "    shuffle=True                \n",
    ")\n",
    "\n",
    "#  创建验证数据集加载器\n",
    "print(f\"  从 '{VALIDATION_DIR}' 创建验证数据集加载器...\")\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False               # 验证集和测试集通常不需要打乱\n",
    ")\n",
    "\n",
    "# 将预处理函数应用到数据管道中，并进行性能优化\n",
    "AUTOTUNE = tf.data.AUTOTUNE \n",
    "\n",
    "# 对训练数据集应用预处理（包含数据增强）\n",
    "train_dataset = train_dataset.map(lambda x, y: preprocess_data(x, y, is_training=True), \n",
    "                                  num_parallel_calls=AUTOTUNE)\n",
    "# 对验证数据集应用预处理（不包含数据增强）\n",
    "validation_dataset = validation_dataset.map(lambda x, y: preprocess_data(x, y, is_training=False), \n",
    "                                            num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "#  使用 .cache() 和 .prefetch() 优化数据加载性能\n",
    "\n",
    "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"\\n训练集和验证集的数据加载器已准备完毕并进行了性能优化。\")\n",
    "print(f\"  - 批次大小 (Batch Size): {BATCH_SIZE}\")\n",
    "print(f\"  - 训练集将应用数据增强和模型预处理。\")\n",
    "print(f\"  - 验证集将只应用模型预处理。\")\n",
    "\n",
    "# (可选) 检查一下数据管道输出的形状\n",
    "for image_batch, label_batch in train_dataset.take(1):\n",
    "    print(f\"\\n检查一批数据的形状:\")\n",
    "    print(f\"  - 图片批次形状: {image_batch.shape}\")\n",
    "    print(f\"  - 标签批次形状: {label_batch.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型编译完成。\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "    # 编译模型\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    loss='categorical_crossentropy',     \n",
    "    metrics=['accuracy']                \n",
    ")\n",
    "print(\"\\n模型编译完成。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678fc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "准备回调函数...\n",
      "\n",
      "即将开始训练，共计 100 个 epochs...\n",
      "Epoch 1/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.5816 - loss: 1.0667\n",
      "Epoch 1: val_accuracy improved from -inf to 0.84229, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 318ms/step - accuracy: 0.5820 - loss: 1.0658 - val_accuracy: 0.8423 - val_loss: 0.4456 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 0.7898 - loss: 0.5500\n",
      "Epoch 2: val_accuracy improved from 0.84229 to 0.86339, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 281ms/step - accuracy: 0.7898 - loss: 0.5499 - val_accuracy: 0.8634 - val_loss: 0.3921 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8248 - loss: 0.4830\n",
      "Epoch 3: val_accuracy improved from 0.86339 to 0.86740, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 251ms/step - accuracy: 0.8248 - loss: 0.4830 - val_accuracy: 0.8674 - val_loss: 0.3856 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.8296 - loss: 0.4547\n",
      "Epoch 4: val_accuracy improved from 0.86740 to 0.87594, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 256ms/step - accuracy: 0.8296 - loss: 0.4547 - val_accuracy: 0.8759 - val_loss: 0.3645 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8395 - loss: 0.4356\n",
      "Epoch 5: val_accuracy improved from 0.87594 to 0.87845, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 250ms/step - accuracy: 0.8395 - loss: 0.4356 - val_accuracy: 0.8785 - val_loss: 0.3542 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8365 - loss: 0.4474\n",
      "Epoch 6: val_accuracy did not improve from 0.87845\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8365 - loss: 0.4474 - val_accuracy: 0.8674 - val_loss: 0.3689 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8377 - loss: 0.4398\n",
      "Epoch 7: val_accuracy improved from 0.87845 to 0.87946, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8378 - loss: 0.4397 - val_accuracy: 0.8795 - val_loss: 0.3513 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8364 - loss: 0.4338\n",
      "Epoch 8: val_accuracy did not improve from 0.87946\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8364 - loss: 0.4338 - val_accuracy: 0.8699 - val_loss: 0.3644 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8410 - loss: 0.4384\n",
      "Epoch 9: val_accuracy improved from 0.87946 to 0.88247, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 245ms/step - accuracy: 0.8410 - loss: 0.4384 - val_accuracy: 0.8825 - val_loss: 0.3513 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8367 - loss: 0.4463\n",
      "Epoch 10: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.8367 - loss: 0.4463 - val_accuracy: 0.8785 - val_loss: 0.3560 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8421 - loss: 0.4384\n",
      "Epoch 11: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 251ms/step - accuracy: 0.8421 - loss: 0.4385 - val_accuracy: 0.8790 - val_loss: 0.3468 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8352 - loss: 0.4375\n",
      "Epoch 12: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8352 - loss: 0.4375 - val_accuracy: 0.8729 - val_loss: 0.3596 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8470 - loss: 0.4102\n",
      "Epoch 13: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 249ms/step - accuracy: 0.8470 - loss: 0.4102 - val_accuracy: 0.8704 - val_loss: 0.3582 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8338 - loss: 0.4374\n",
      "Epoch 14: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8338 - loss: 0.4374 - val_accuracy: 0.8704 - val_loss: 0.3623 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8381 - loss: 0.4456\n",
      "Epoch 15: val_accuracy did not improve from 0.88247\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.8380 - loss: 0.4456 - val_accuracy: 0.8764 - val_loss: 0.3629 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8430 - loss: 0.4232\n",
      "Epoch 16: val_accuracy did not improve from 0.88247\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.8430 - loss: 0.4232 - val_accuracy: 0.8724 - val_loss: 0.3546 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8486 - loss: 0.4109\n",
      "Epoch 17: val_accuracy improved from 0.88247 to 0.88297, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8486 - loss: 0.4108 - val_accuracy: 0.8830 - val_loss: 0.3500 - learning_rate: 2.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8461 - loss: 0.4173\n",
      "Epoch 18: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.8461 - loss: 0.4173 - val_accuracy: 0.8785 - val_loss: 0.3508 - learning_rate: 2.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8502 - loss: 0.4121\n",
      "Epoch 19: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 244ms/step - accuracy: 0.8502 - loss: 0.4121 - val_accuracy: 0.8820 - val_loss: 0.3451 - learning_rate: 2.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.8434 - loss: 0.4121\n",
      "Epoch 20: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.8434 - loss: 0.4121 - val_accuracy: 0.8769 - val_loss: 0.3471 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8509 - loss: 0.4078\n",
      "Epoch 21: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8509 - loss: 0.4078 - val_accuracy: 0.8754 - val_loss: 0.3499 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.8514 - loss: 0.4008\n",
      "Epoch 22: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 268ms/step - accuracy: 0.8514 - loss: 0.4008 - val_accuracy: 0.8805 - val_loss: 0.3468 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8540 - loss: 0.4041\n",
      "Epoch 23: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 278ms/step - accuracy: 0.8540 - loss: 0.4041 - val_accuracy: 0.8754 - val_loss: 0.3514 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8560 - loss: 0.3893\n",
      "Epoch 24: val_accuracy did not improve from 0.88297\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 285ms/step - accuracy: 0.8560 - loss: 0.3894 - val_accuracy: 0.8785 - val_loss: 0.3460 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8581 - loss: 0.3908\n",
      "Epoch 25: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 251ms/step - accuracy: 0.8581 - loss: 0.3908 - val_accuracy: 0.8795 - val_loss: 0.3400 - learning_rate: 4.0000e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8548 - loss: 0.3899\n",
      "Epoch 26: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 257ms/step - accuracy: 0.8548 - loss: 0.3899 - val_accuracy: 0.8820 - val_loss: 0.3393 - learning_rate: 4.0000e-05\n",
      "Epoch 27/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8617 - loss: 0.3806\n",
      "Epoch 27: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 246ms/step - accuracy: 0.8617 - loss: 0.3806 - val_accuracy: 0.8830 - val_loss: 0.3375 - learning_rate: 4.0000e-05\n",
      "Epoch 28/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8509 - loss: 0.4003\n",
      "Epoch 28: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8509 - loss: 0.4003 - val_accuracy: 0.8830 - val_loss: 0.3382 - learning_rate: 4.0000e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8631 - loss: 0.3836\n",
      "Epoch 29: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 256ms/step - accuracy: 0.8630 - loss: 0.3836 - val_accuracy: 0.8830 - val_loss: 0.3375 - learning_rate: 4.0000e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8571 - loss: 0.3889\n",
      "Epoch 30: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 256ms/step - accuracy: 0.8571 - loss: 0.3889 - val_accuracy: 0.8825 - val_loss: 0.3379 - learning_rate: 4.0000e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417ms/step - accuracy: 0.8534 - loss: 0.3908\n",
      "Epoch 31: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 518ms/step - accuracy: 0.8534 - loss: 0.3908 - val_accuracy: 0.8830 - val_loss: 0.3377 - learning_rate: 4.0000e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8587 - loss: 0.3874\n",
      "Epoch 32: val_accuracy did not improve from 0.88297\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 431ms/step - accuracy: 0.8587 - loss: 0.3875 - val_accuracy: 0.8805 - val_loss: 0.3391 - learning_rate: 4.0000e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.8542 - loss: 0.3923\n",
      "Epoch 33: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 401ms/step - accuracy: 0.8541 - loss: 0.3923 - val_accuracy: 0.8825 - val_loss: 0.3377 - learning_rate: 8.0000e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.8615 - loss: 0.3851\n",
      "Epoch 34: val_accuracy did not improve from 0.88297\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 406ms/step - accuracy: 0.8615 - loss: 0.3851 - val_accuracy: 0.8830 - val_loss: 0.3368 - learning_rate: 8.0000e-06\n",
      "Epoch 35/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8568 - loss: 0.3928\n",
      "Epoch 35: val_accuracy improved from 0.88297 to 0.88348, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 249ms/step - accuracy: 0.8568 - loss: 0.3928 - val_accuracy: 0.8835 - val_loss: 0.3357 - learning_rate: 8.0000e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8497 - loss: 0.3952\n",
      "Epoch 36: val_accuracy did not improve from 0.88348\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8498 - loss: 0.3952 - val_accuracy: 0.8835 - val_loss: 0.3354 - learning_rate: 8.0000e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8590 - loss: 0.3874\n",
      "Epoch 37: val_accuracy improved from 0.88348 to 0.88398, saving model to saved_models/best_model.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 254ms/step - accuracy: 0.8589 - loss: 0.3874 - val_accuracy: 0.8840 - val_loss: 0.3357 - learning_rate: 8.0000e-06\n",
      "Epoch 38/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8582 - loss: 0.3913\n",
      "Epoch 38: val_accuracy did not improve from 0.88398\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8582 - loss: 0.3913 - val_accuracy: 0.8840 - val_loss: 0.3358 - learning_rate: 8.0000e-06\n",
      "Epoch 39/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8631 - loss: 0.3788\n",
      "Epoch 39: val_accuracy did not improve from 0.88398\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8631 - loss: 0.3788 - val_accuracy: 0.8840 - val_loss: 0.3357 - learning_rate: 8.0000e-06\n",
      "Epoch 40/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8611 - loss: 0.3969\n",
      "Epoch 40: val_accuracy did not improve from 0.88398\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 252ms/step - accuracy: 0.8611 - loss: 0.3969 - val_accuracy: 0.8835 - val_loss: 0.3353 - learning_rate: 8.0000e-06\n",
      "Epoch 41/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8531 - loss: 0.3925\n",
      "Epoch 41: val_accuracy improved from 0.88398 to 0.88448, saving model to saved_models/best_model.keras\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 249ms/step - accuracy: 0.8531 - loss: 0.3925 - val_accuracy: 0.8845 - val_loss: 0.3357 - learning_rate: 8.0000e-06\n",
      "Epoch 42/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.8585 - loss: 0.3781\n",
      "Epoch 42: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 254ms/step - accuracy: 0.8585 - loss: 0.3781 - val_accuracy: 0.8840 - val_loss: 0.3358 - learning_rate: 1.6000e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.8598 - loss: 0.3821\n",
      "Epoch 43: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 251ms/step - accuracy: 0.8597 - loss: 0.3821 - val_accuracy: 0.8840 - val_loss: 0.3358 - learning_rate: 1.6000e-06\n",
      "Epoch 44/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8529 - loss: 0.3823\n",
      "Epoch 44: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 246ms/step - accuracy: 0.8529 - loss: 0.3823 - val_accuracy: 0.8835 - val_loss: 0.3357 - learning_rate: 1.6000e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.8529 - loss: 0.3934\n",
      "Epoch 45: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 251ms/step - accuracy: 0.8529 - loss: 0.3934 - val_accuracy: 0.8835 - val_loss: 0.3356 - learning_rate: 1.6000e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.8546 - loss: 0.3972\n",
      "Epoch 46: val_accuracy did not improve from 0.88448\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 248ms/step - accuracy: 0.8546 - loss: 0.3972 - val_accuracy: 0.8835 - val_loss: 0.3356 - learning_rate: 1.6000e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.8573 - loss: 0.3861\n",
      "Epoch 47: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 247ms/step - accuracy: 0.8573 - loss: 0.3861 - val_accuracy: 0.8830 - val_loss: 0.3357 - learning_rate: 1.0000e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step - accuracy: 0.8580 - loss: 0.3867\n",
      "Epoch 48: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 262ms/step - accuracy: 0.8580 - loss: 0.3868 - val_accuracy: 0.8835 - val_loss: 0.3356 - learning_rate: 1.0000e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.8527 - loss: 0.3943\n",
      "Epoch 49: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 277ms/step - accuracy: 0.8527 - loss: 0.3942 - val_accuracy: 0.8830 - val_loss: 0.3357 - learning_rate: 1.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.8560 - loss: 0.3911\n",
      "Epoch 50: val_accuracy did not improve from 0.88448\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 276ms/step - accuracy: 0.8560 - loss: 0.3911 - val_accuracy: 0.8840 - val_loss: 0.3358 - learning_rate: 1.0000e-06\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "\n",
      "模型训练完成！\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "print(\"\\n准备回调函数...\")\n",
    "\n",
    "#  ModelCheckpoint: 保存训练过程中表现最好的模型\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    'saved_models/best_model.keras', # 使用 .keras 格式\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1 # 打印保存信息\n",
    ")\n",
    "\n",
    "#  EarlyStopping: 在验证集性能不再提升时提前停止训练，防止过拟合\n",
    "\n",
    "early_stopping_cb = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#  ReduceLROnPlateau: 在学习停滞时降低学习率\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-6, # 学习率最小不低于 1e-6\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 将所有回调函数放入一个列表\n",
    "callbacks_list = [checkpoint_cb, early_stopping_cb, reduce_lr_cb]\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "\n",
    "# --- 开始训练！ ---\n",
    "\n",
    "print(f\"\\n即将开始训练，共计 {EPOCHS} 个 epochs...\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "print(\"\\n模型训练完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa1778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从 'saved_models/best_model.keras' 加载表现最佳的模型...\n",
      "模型加载成功！\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#  加载最佳模型 \n",
    "\n",
    "best_model_path = 'saved_models/best_model.keras'\n",
    "\n",
    "print(f\"正在从 '{best_model_path}' 加载表现最佳的模型...\")\n",
    "try:\n",
    "    best_model = load_model(best_model_path)\n",
    "    print(\"模型加载成功！\")\n",
    "except Exception as e:\n",
    "    print(f\"加载模型失败，请检查路径是否正确: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c39f4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "从 'C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\test' 加载测试数据...\n",
      "Found 1992 files belonging to 4 classes.\n",
      "\n",
      "在测试集上评估最终模型性能...\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 224ms/step - accuracy: 0.8663 - loss: 0.3756\n",
      "\n",
      "测试集损失 (Test Loss): 0.3046\n",
      "测试集准确率 (Test Accuracy): 0.8976\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "TEST_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\test\"  \n",
    "\n",
    "# 导入并使用你训练时用的同一个模型预处理函数\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as model_specific_preprocess_input\n",
    "\n",
    "def preprocess_for_eval(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = model_specific_preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "print(f\"\\n从 '{TEST_DIR}' 加载测试数据...\")\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    interpolation='nearest',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # 测试时不需要打乱数据\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess_for_eval, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\n在测试集上评估最终模型性能...\")\n",
    "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"\\n测试集损失 (Test Loss): {test_loss:.4f}\")\n",
    "print(f\"测试集准确率 (Test Accuracy): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 微调阶段开始 ---\n",
      "\n",
      "[步骤 1/7] 正在从 'saved_models/best_model.keras' 加载模型...\n",
      "模型加载成功。\n",
      "\n",
      "[步骤 2/7] 正在准备数据加载器...\n",
      "Found 9291 files belonging to 4 classes.\n",
      "Found 1991 files belonging to 4 classes.\n",
      "数据加载器准备完毕。\n",
      "\n",
      "[步骤 3/7] 正在解冻模型层以便微调...\n",
      "模型前 100 层已冻结，后续层将参与微调。\n",
      "\n",
      "[步骤 4/7] 正在使用低学习率 (1e-05) 重新编译模型...\n",
      "模型重新编译完成。\n",
      "\n",
      "[步骤 5/7] 正在设置回调函数并准备开始微调...\n",
      "\n",
      "即将开始微调训练，最多进行 30 个 epochs...\n",
      "Epoch 1/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.8418 - loss: 0.4595\n",
      "Epoch 1: val_accuracy improved from -inf to 0.88599, saving model to saved_models/best_model_finetuned.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 275ms/step - accuracy: 0.8418 - loss: 0.4595 - val_accuracy: 0.8860 - val_loss: 0.3371 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.8325 - loss: 0.4531\n",
      "Epoch 2: val_accuracy did not improve from 0.88599\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 234ms/step - accuracy: 0.8326 - loss: 0.4530 - val_accuracy: 0.8855 - val_loss: 0.3354 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.8404 - loss: 0.4434\n",
      "Epoch 3: val_accuracy improved from 0.88599 to 0.88800, saving model to saved_models/best_model_finetuned.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 231ms/step - accuracy: 0.8404 - loss: 0.4434 - val_accuracy: 0.8880 - val_loss: 0.3338 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.8344 - loss: 0.4425\n",
      "Epoch 4: val_accuracy did not improve from 0.88800\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 364ms/step - accuracy: 0.8344 - loss: 0.4425 - val_accuracy: 0.8875 - val_loss: 0.3330 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.8385 - loss: 0.4446\n",
      "Epoch 5: val_accuracy improved from 0.88800 to 0.88950, saving model to saved_models/best_model_finetuned.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 429ms/step - accuracy: 0.8385 - loss: 0.4446 - val_accuracy: 0.8895 - val_loss: 0.3320 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.8414 - loss: 0.4390\n",
      "Epoch 6: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 401ms/step - accuracy: 0.8414 - loss: 0.4390 - val_accuracy: 0.8870 - val_loss: 0.3315 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.8365 - loss: 0.4509\n",
      "Epoch 7: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 392ms/step - accuracy: 0.8365 - loss: 0.4509 - val_accuracy: 0.8865 - val_loss: 0.3304 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - accuracy: 0.8421 - loss: 0.4376\n",
      "Epoch 8: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 392ms/step - accuracy: 0.8421 - loss: 0.4376 - val_accuracy: 0.8885 - val_loss: 0.3296 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.8456 - loss: 0.4383\n",
      "Epoch 9: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 399ms/step - accuracy: 0.8456 - loss: 0.4382 - val_accuracy: 0.8880 - val_loss: 0.3291 - learning_rate: 1.0000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.8421 - loss: 0.4405\n",
      "Epoch 10: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 404ms/step - accuracy: 0.8421 - loss: 0.4404 - val_accuracy: 0.8875 - val_loss: 0.3285 - learning_rate: 1.0000e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.8435 - loss: 0.4371\n",
      "Epoch 11: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 401ms/step - accuracy: 0.8435 - loss: 0.4371 - val_accuracy: 0.8875 - val_loss: 0.3282 - learning_rate: 1.0000e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.8395 - loss: 0.4377\n",
      "Epoch 12: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 402ms/step - accuracy: 0.8395 - loss: 0.4376 - val_accuracy: 0.8885 - val_loss: 0.3278 - learning_rate: 1.0000e-05\n",
      "Epoch 13/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.8396 - loss: 0.4482\n",
      "Epoch 13: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 406ms/step - accuracy: 0.8396 - loss: 0.4482 - val_accuracy: 0.8880 - val_loss: 0.3272 - learning_rate: 1.0000e-05\n",
      "Epoch 14/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.8512 - loss: 0.4165\n",
      "Epoch 14: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 401ms/step - accuracy: 0.8511 - loss: 0.4165 - val_accuracy: 0.8860 - val_loss: 0.3261 - learning_rate: 1.0000e-05\n",
      "Epoch 15/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.8402 - loss: 0.4417\n",
      "Epoch 15: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 398ms/step - accuracy: 0.8402 - loss: 0.4416 - val_accuracy: 0.8870 - val_loss: 0.3252 - learning_rate: 1.0000e-05\n",
      "Epoch 16/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.8357 - loss: 0.4363\n",
      "Epoch 16: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 407ms/step - accuracy: 0.8357 - loss: 0.4362 - val_accuracy: 0.8870 - val_loss: 0.3252 - learning_rate: 1.0000e-05\n",
      "Epoch 17/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.8376 - loss: 0.4302\n",
      "Epoch 17: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 399ms/step - accuracy: 0.8377 - loss: 0.4302 - val_accuracy: 0.8890 - val_loss: 0.3250 - learning_rate: 1.0000e-05\n",
      "Epoch 18/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.8506 - loss: 0.4190\n",
      "Epoch 18: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 388ms/step - accuracy: 0.8506 - loss: 0.4190 - val_accuracy: 0.8880 - val_loss: 0.3252 - learning_rate: 1.0000e-05\n",
      "Epoch 19/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step - accuracy: 0.8489 - loss: 0.4272\n",
      "Epoch 19: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 388ms/step - accuracy: 0.8489 - loss: 0.4271 - val_accuracy: 0.8880 - val_loss: 0.3247 - learning_rate: 1.0000e-05\n",
      "Epoch 20/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.8411 - loss: 0.4354\n",
      "Epoch 20: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 384ms/step - accuracy: 0.8411 - loss: 0.4354 - val_accuracy: 0.8875 - val_loss: 0.3243 - learning_rate: 1.0000e-05\n",
      "Epoch 21/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.8368 - loss: 0.4365\n",
      "Epoch 21: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 386ms/step - accuracy: 0.8368 - loss: 0.4365 - val_accuracy: 0.8885 - val_loss: 0.3238 - learning_rate: 1.0000e-05\n",
      "Epoch 22/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.8490 - loss: 0.4155\n",
      "Epoch 22: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 404ms/step - accuracy: 0.8490 - loss: 0.4155 - val_accuracy: 0.8890 - val_loss: 0.3230 - learning_rate: 1.0000e-05\n",
      "Epoch 23/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.8388 - loss: 0.4308\n",
      "Epoch 23: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 408ms/step - accuracy: 0.8388 - loss: 0.4308 - val_accuracy: 0.8875 - val_loss: 0.3222 - learning_rate: 1.0000e-05\n",
      "Epoch 24/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.8423 - loss: 0.4272\n",
      "Epoch 24: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 434ms/step - accuracy: 0.8423 - loss: 0.4272 - val_accuracy: 0.8885 - val_loss: 0.3222 - learning_rate: 1.0000e-05\n",
      "Epoch 25/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8444 - loss: 0.4314\n",
      "Epoch 25: val_accuracy did not improve from 0.88950\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 1s/step - accuracy: 0.8445 - loss: 0.4313 - val_accuracy: 0.8880 - val_loss: 0.3224 - learning_rate: 1.0000e-05\n",
      "Epoch 26/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.8506 - loss: 0.4240\n",
      "Epoch 26: val_accuracy improved from 0.88950 to 0.89051, saving model to saved_models/best_model_finetuned.keras\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 242ms/step - accuracy: 0.8506 - loss: 0.4240 - val_accuracy: 0.8905 - val_loss: 0.3219 - learning_rate: 1.0000e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8465 - loss: 0.4215\n",
      "Epoch 27: val_accuracy did not improve from 0.89051\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 243ms/step - accuracy: 0.8465 - loss: 0.4215 - val_accuracy: 0.8890 - val_loss: 0.3220 - learning_rate: 1.0000e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.8463 - loss: 0.4261\n",
      "Epoch 28: val_accuracy did not improve from 0.89051\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 238ms/step - accuracy: 0.8463 - loss: 0.4261 - val_accuracy: 0.8905 - val_loss: 0.3210 - learning_rate: 1.0000e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8458 - loss: 0.4211\n",
      "Epoch 29: val_accuracy did not improve from 0.89051\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 222ms/step - accuracy: 0.8458 - loss: 0.4211 - val_accuracy: 0.8895 - val_loss: 0.3212 - learning_rate: 1.0000e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8457 - loss: 0.4232\n",
      "Epoch 30: val_accuracy did not improve from 0.89051\n",
      "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 220ms/step - accuracy: 0.8457 - loss: 0.4231 - val_accuracy: 0.8875 - val_loss: 0.3222 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\n",
      "模型微调完成！\n",
      "\n",
      "[步骤 6/7] 正在评估微调后的最佳模型...\n",
      "Found 1992 files belonging to 4 classes.\n",
      "\n",
      "在测试集上评估微调后的模型性能:\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 203ms/step - accuracy: 0.8623 - loss: 0.3795\n",
      "\n",
      "微调后 - 测试集损失: 0.2901\n",
      "微调后 - 测试集准确率: 0.9036\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 配置参数 (请根据你的项目情况进行修改)\n",
    "\n",
    "INITIAL_MODEL_PATH = 'saved_models/best_model.keras'\n",
    "\n",
    "FINETUNED_MODEL_SAVE_PATH = 'saved_models/best_model_finetuned.keras'\n",
    "\n",
    "# 数据集目录路径\n",
    "TRAIN_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\train\"\n",
    "VALIDATION_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\validation\"\n",
    "TEST_DIR = r\"C:\\Users\\Lenovo\\Desktop\\final_split_dataset\\test\"\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# 意味着前100层保持冻结，微调顶部的约55层。\n",
    "FINE_TUNE_AT_LAYER = 100\n",
    "\n",
    "LOW_LEARNING_RATE = 1e-5 \n",
    "\n",
    "FINE_TUNE_EPOCHS = 30 \n",
    "\n",
    "# 加载第一阶段训练好的模型\n",
    "\n",
    "print(\"--- 微调阶段开始 ---\")\n",
    "print(f\"\\n[步骤 1/7] 正在从 '{INITIAL_MODEL_PATH}' 加载模型...\")\n",
    "\n",
    "if not os.path.exists(INITIAL_MODEL_PATH):\n",
    "    print(f\"错误: 模型文件未找到: {INITIAL_MODEL_PATH}\")\n",
    "    print(\"请先完成第一阶段的训练，并确保最佳模型已保存。\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "model = load_model(INITIAL_MODEL_PATH)\n",
    "print(\"模型加载成功。\")\n",
    "\n",
    "# 准备数据加载器/数据管道 (与训练时类似)\n",
    "\n",
    "print(f\"\\n[步骤 2/7] 正在准备数据加载器...\")\n",
    "\n",
    "# 导入并使用你训练时用的同一个模型预处理函数 (例如MobileNetV2的)\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as model_specific_preprocess_input\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 定义数据增强管道 (与之前一致)\n",
    "data_augmentation_pipeline = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "], name=\"data_augmentation\")\n",
    "\n",
    "def preprocess_data(image, label, is_training=False):\n",
    "    image = tf.cast(image, tf.float32) # 确保数据类型正确\n",
    "    if is_training:\n",
    "        image = data_augmentation_pipeline(image, training=True)\n",
    "    image = model_specific_preprocess_input(image)\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# 创建训练和验证数据集\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR, labels='inferred', label_mode='categorical',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, shuffle=True\n",
    ").map(lambda x, y: preprocess_data(x, y, is_training=True), num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    VALIDATION_DIR, labels='inferred', label_mode='categorical',\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, shuffle=False\n",
    ").map(lambda x, y: preprocess_data(x, y, is_training=False), num_parallel_calls=AUTOTUNE).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "print(\"数据加载器准备完毕。\")\n",
    "\n",
    "# 解冻基础模型并设置要微调的层\n",
    "\n",
    "print(f\"\\n[步骤 3/7] 正在解冻模型层以便微调...\")\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:FINE_TUNE_AT_LAYER]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"模型前 {FINE_TUNE_AT_LAYER} 层已冻结，后续层将参与微调。\")\n",
    "\n",
    "# 使用低学习率重新编译模型\n",
    "\n",
    "print(f\"\\n[步骤 4/7] 正在使用低学习率 ({LOW_LEARNING_RATE}) 重新编译模型...\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=LOW_LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print(\"模型重新编译完成。\")\n",
    "\n",
    "\n",
    "\n",
    "#  定义回调函数并开始微调\n",
    "\n",
    "print(f\"\\n[步骤 5/7] 正在设置回调函数并准备开始微调...\")\n",
    "\n",
    "# 定义新的ModelCheckpoint，将微调后的最佳模型保存到新文件\n",
    "finetune_checkpoint_cb = ModelCheckpoint(\n",
    "    FINETUNED_MODEL_SAVE_PATH,\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# EarlyStopping 和 ReduceLROnPlateau 可以继续使用之前的定义\n",
    "early_stopping_cb = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n",
    "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7, verbose=1)\n",
    "\n",
    "callbacks_list = [finetune_checkpoint_cb, early_stopping_cb, reduce_lr_cb]\n",
    "\n",
    "# 开始微调训练\n",
    "print(f\"\\n即将开始微调训练，最多进行 {FINE_TUNE_EPOCHS} 个 epochs...\")\n",
    "\n",
    "history_fine_tune = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "print(\"\\n模型微调完成！\")\n",
    "\n",
    "\n",
    "print(f\"\\n[步骤 6/7] 正在评估微调后的最佳模型...\")\n",
    "\n",
    "# 加载微调后保存的最佳模型\n",
    "try:\n",
    "    finetuned_model = load_model(FINETUNED_MODEL_SAVE_PATH)\n",
    "\n",
    "    # 创建测试集加载器\n",
    "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        TEST_DIR, labels='inferred', label_mode='categorical',\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH), batch_size=BATCH_SIZE, shuffle=False\n",
    "    ).map(lambda x, y: preprocess_data(x, y, is_training=False), num_parallel_calls=AUTOTUNE).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    # 评估\n",
    "    print(\"\\n在测试集上评估微调后的模型性能:\")\n",
    "    test_loss, test_accuracy = finetuned_model.evaluate(test_dataset)\n",
    "    print(f\"\\n微调后 - 测试集损失: {test_loss:.4f}\")\n",
    "    print(f\"微调后 - 测试集准确率: {test_accuracy:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"评估微调后的模型时出错: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d0fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
